{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2087b988-6fe9-4c3d-bb78-8749ab2ed64d",
   "metadata": {},
   "source": [
    "STUDENT: Joel S. Mollel\n",
    "\n",
    "NUMBER: C00313599\n",
    "\n",
    "ALGORITHM: K-Nearest Neighbour\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547739b6-8707-485d-aaa5-1d7d35e4ca35",
   "metadata": {},
   "source": [
    "Provided with K-Nearest neighbour Code, we are required to\n",
    "\n",
    "i) make sure it runs\n",
    "\n",
    "ii)Change some hyperparameters and see the impact\n",
    "\n",
    "iii)Use another dataset and perform other operations, and simulate as an app\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5515080f-674a-402f-80c9-d6fa20c4da67",
   "metadata": {},
   "source": [
    "(i) Making the code running\n",
    "After combining the code from the page it worked, trained the model and calculated accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec58af1-bfeb-4541-af04-f64eac17b2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to get the design matrix (features) X\n",
    "def get_X(data):\n",
    "    \"\"\"Return model design matrix X\"\"\"\n",
    "    return data.filter(like='X').values\n",
    "\n",
    "# Function to get the target variable y\n",
    "def get_y(data):\n",
    "    \"\"\"Return dependent variable y\"\"\"\n",
    "    y = data.Close.pct_change(48).shift(-48)  # Returns after roughly two days\n",
    "    y[y.between(-.004, .004)] = 0             # Devalue returns smaller than 0.4%\n",
    "    y[y > 0] = 1\n",
    "    y[y < 0] = -1\n",
    "    return y\n",
    "\n",
    "# Function to clean X and y (remove NaNs)\n",
    "def get_clean_Xy(df):\n",
    "    \"\"\"Return (X, y) cleaned of NaN values\"\"\"\n",
    "    X = get_X(df)\n",
    "    y = get_y(df).values\n",
    "    isnan = np.isnan(y)\n",
    "    X = X[~isnan]\n",
    "    y = y[~isnan]\n",
    "    return X, y\n",
    "\n",
    "# Simulate some sample data (you would replace this with your real data)\n",
    "# Assuming that the data contains columns like 'X1', 'X2', 'Close', etc.\n",
    "np.random.seed(0)\n",
    "data = pd.DataFrame({\n",
    "    'X1': np.random.rand(1000),\n",
    "    'X2': np.random.rand(1000),\n",
    "    'Close': np.random.rand(1000) * 100  # Simulating a 'Close' price column\n",
    "})\n",
    "\n",
    "# Get cleaned X and y\n",
    "X, y = get_clean_Xy(data)\n",
    "\n",
    "# Split data into training and test sets (50% split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "\n",
    "# Initialize and train the k-NN classifier with 7 neighbors\n",
    "clf = KNeighborsClassifier(7)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Plot true vs predicted values\n",
    "_ = pd.DataFrame({'y_true': y_test, 'y_pred': y_pred}).plot(figsize=(15, 2), alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "# Print classification accuracy\n",
    "print('Classification accuracy: ', np.mean(y_test == y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
